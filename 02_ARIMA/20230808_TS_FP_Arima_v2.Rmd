---
title: "TS - Arima File"
author: "Kshitij Mittal"
date: "2023-08-08"
output: html_document
---

# ARIMA MODELING
```{r setup, include=FALSE, cache=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(warning = FALSE, message = FALSE) 
```


## Importing Libraries
```{r, message=FALSE, echo=FALSE}
# Load required packages
library(readxl)
library(ggplot2)
library(forecast)
library(ggseas)
library(zoo)
library(tseries)
library(fpp)
library(MASS)
library(ggplot2)

library(TSA)
```

## Loading Data
```{r}
# Read the Excel file
data <- read_excel("TS_Project_Data.xlsx")

# Convert the 'Period' column to year-quarter format
data$Period <- as.yearqtr(data$Period, format = "%Y Q%q")

# Convert "Period" to a Date object
data$Period <- as.Date(paste(data$Period, "01", sep = "-"), format = "%Y Q%m-%d")

# Extract year and quarter components
data$Year <- as.numeric(format(data$Period, "%Y"))
data$Quarter <- as.numeric(format(data$Period, "%m"))

# Create a time series object
ts_gdp <- ts(data$GDP, start = c(data$Year[1], data$Quarter[1]), frequency = 4)

#Plotting the time series
tsdisplay(ts_gdp, main = "UK GDP between 1955 and 2015")
```
## Assumption 1 - Constant Variance using BoxPlot Transformation

```{r}
# Load required packages
bc_lambda=BoxCox.lambda(ts_gdp)
ts_gdp %>% BoxCox(lambda = bc_lambda) %>% autoplot()
ts_gpd_bc = BoxCox(ts_gdp, lambda = bc_lambda)

# If the data show variation that increases or decreases with the level of the series, then a boxcox transformation can be useful.
```

## Assumption 2 - Stationarity is important for fitting Arima Models
ARIMA uses previous lags of series to model its behavior; therefore, modeling stable series with consistent properties involves less uncertainty.

```{r}
# RUNNING ADF AND KPISS TEST
adf_test <- adf.test(ts_gpd_bc)
print(adf_test)
kpss_test <- kpss.test(ts_gpd_bc)
print(kpss_test)

```

Data can be seen as non-stationary

```{r}
# Differencing the time series
ts_gdp_bc_diff <- diff(ts_gpd_bc)

# Check the stationarity of the differenced series using ADF and KPSS tests
adf_test_result_diff <- adf.test(ts_gdp_bc_diff)
kpss_test_result_diff <- kpss.test(ts_gdp_bc_diff)

print(adf_test_result_diff)
print(kpss_test_result_diff)

tsdisplay(ts_gdp_bc_diff)
```

Data seems stationary post single order differencing.
From observations, we can see an exponential decay in the ACF plot, along with hard drops in the PACF plot.
This indicates that the process might be an Autoregressive process of Order 3 

Since both ACF and PACF are trailing off, this model can also be an ARMA model 

## Dividing into Train and Test prior to Model Fitting
```{r}
# Perform train-test split
ts_gdp_train <- window(ts_gdp, end = c(2010, 4))  # Training data until 2009 Q4
ts_gdp_test <- window(ts_gdp, start = c(2011, 1)) # Test data from 2010 Q1 onwards
number_of_forecasts = 20

# Plot time series of train and test data
ggplot() +
  geom_line(data = as.data.frame(ts_gdp_train), aes(x = time(ts_gdp_train), y = ts_gdp_train), color = "blue", linetype = "solid", size = 1) +
  geom_line(data = as.data.frame(ts_gdp_test), aes(x = time(ts_gdp_test), y = ts_gdp_test), color = "red", linetype = "solid", size = 1) +
  labs(title = "Time Series of Train and Test Data", x = "Year", y = "Value") +
  theme_minimal()
```

## Model Fitting - Non Seasonal Auto Arima

```{r}
auto.arima(ts_gdp_train,seasonal=FALSE, lambda = bc_lambda, trace = TRUE)

# RUNNING EACF ON FIRST ORDER DIFFERENCE TRAIN DATA
eacf(diff(ts_gdp_train))
```

Auto Arima is giving a best model of ARIMA(0,1,3) - indicating the absence of an auto-regression component and only moving average.
Differencing (Integration) of order 1 is consistent with our prior observations.

EACF run for first order differenced data also indicates using (1,1) and (1,3) models. We can run these also to check if we observe better model fits


```{r}
fit_ar1=Arima(ts_gdp_train, order=c(0,1,3), include.drift = TRUE, lambda = bc_lambda) 
fit_ar2=Arima(ts_gdp_train, order=c(1,1,1), include.drift = TRUE, lambda = bc_lambda) 
fit_ar3=Arima(ts_gdp_train, order=c(1,1,3), include.drift = TRUE, lambda = bc_lambda) 

fit_ar1$aicc
fit_ar2$aicc
fit_ar3$aicc
```

We are still getting the Auto Arima indicated ARIMA(0,1,3) model with drift.
We will now check forecasts from this model

## Analysing Forecasts from the Non-Seasonal Arima Model
```{r}
forecast_arima=forecast(fit_ar1, h= number_of_forecasts)
plot(forecast_arima, main = "Arima(0,1,3) Forecasted Values")

# Check residuals
checkresiduals(residuals(forecast_arima))
```
The residuals look normally distributed with no siginficant auto-correlation at any lags.
The model also passes the Ljung Box test, and we cannot reject the null hypothesis that there is no auto-correlation in the residuals.

```{r}
# Checking for RMSE
squared_diff_arima <- (forecast_arima$mean - ts_gdp_test)^2
rmse_arima <- sqrt(mean(squared_diff_arima))
accuracy(forecast_arima, ts_gdp_test)

# Print RMSE
print(paste("RMSE:", rmse_arima))
```


```{r}
# CROSS VALIDATION

k=160                   # minimum data length for fitting a model
n=length(ts_gdp_train) # number of data points
p=4                    # Period
H=1 # Horizon Period

st <- tsp(ts_gdp_train)[1]+(k-2)/p #  gives the start time in time units,

# MAE
mae_1 = matrix(NA,n-k,H)
mae_2 = matrix(NA,n-k,H)

# ERROR
err_1 = matrix(NA,n-k,H)
err_2 = matrix(NA,n-k,H)

# ERROR
rmse_1 = numeric()
rmse_2 = numeric()

# AIC
aicc_1 = numeric()
aicc_2 = numeric()
```


```{r}

for(i in 1:(n-k))
{
  
  ### One Month rolling forecasting
  
  # Expanding Window 
  train_1 <- window(ts_gdp_train, end=st + i/p)  ## Window Length: k+i
  
  # Sliding Window - keep the training window of fixed length. 
  # The training set always consists of k observations.
  train_2 <- window(ts_gdp_train, start=st+(i-k+1)/p, end=st+i/p)  ## Window Length: k
  
  # Test Data
  test <- window(ts_gdp_train, start=st + (i+1)/p, end=st + (i+H)/p) ## Window Length: H

  if (i<(n-k)) 
    {
  cat(c("*** CV", i,":","len(Expanding Window):",length(train_1), "len(Sliding Window):",length(train_2), "len(Test):",length(test),'\n'  ))
  cat(c("*** TRAIN -  Expanding WIndow:",tsp(train_1)[1],'-',tsp(train_1)[2],'\n'))
  cat(c("*** TRAIN - Sliding WIndow:",tsp(train_2)[1],'-',tsp(train_2)[2],'\n'))
  cat(c("*** TEST:",tsp(test)[1],'-',tsp(test)[2],'\n'))
  cat("*************************** \n \n")
  }
  
  # ARIMA Model - Expanding Window
  fit_1 <- Arima(train_1, order=c(0,1,3), include.drift=TRUE, lambda=bc_lambda, method="ML")
  fcast_1 <- forecast(fit_1, h=H)
  
  # ARIMA Model - Sliding Window
  fit_2 <- Arima(train_2, order=c(0,1,3), include.drift=TRUE, lambda=bc_lambda, method="ML")
  fcast_2 <- forecast(fit_2, h=H)
  
  # MAE
  mae_1[i,1:length(test)] <- abs(fcast_1[['mean']]-test)
  mae_2[i,1:length(test)] <- abs(fcast_2[['mean']]-test)
  # RMSE
  err_1[i,1:length(test)] <- fcast_1[['mean']]-test
  err_2[i,1:length(test)] <- fcast_2[['mean']]-test
  
  
  
  
  # AIC
  aicc_1 <- append(aicc_1, fit_1$aicc)
  aicc_2 <- append(aicc_2, fit_2$aicc)
  }
```



```{r}
# CROSS VALIDATION

library(graphics)
library(fpp)
library(igraph)
plot(1:1, colMeans(mae_1,na.rm=TRUE), type="l",col=1,xlab="horizon", 
     ylab="MAE", main = 'Mean Absolute Forecast Error (MAE) vs forecast horizon')
lines(1:1, colMeans(mae_2,na.rm=TRUE), type="l",col=2)

legend("bottomright",legend=c("ARIMA - Expanding Window","ARIMA - Sliding Window") ,col=1:2,lty=1)
```


```{r}
# RMSE ACROSS ITERATIONS

library(graphics)
library(fpp)
library(igraph)
plot(0:63, mae_1, type="l",col=1,xlab="Iterations", 
     ylab="MAE", main = 'Mean Absolute Forecast Error (MAE) vs Iterations')
lines(0:63, mae_2, type="l",col=2)

legend("topleft",legend=c("ARIMA - Expanding Window","ARIMA - Sliding Window") ,col=1:2,lty=1)
```


```{r}

plot(1:20, sqrt(colMeans((err_1)^2,na.rm=TRUE)), type="l",col=1,xlab="horizon", 
     ylab="RMSE", main = 'Root-square Forecast Error (RMSE) vs forecast horizon')
lines(1:20, sqrt(colMeans((err_2)^2,na.rm=TRUE)), type="l",col=2)

legend("bottomright",legend=c("ARIMA - Expanding Window","ARIMA - Sliding Window"),col=1:4,lty=1)
```